From a255899c8c5f8cce50668a2caf7694eae0c88194 Mon Sep 17 00:00:00 2001
From: "River, Li" <river.li@intel.com>
Date: Thu, 24 Dec 2015 18:43:53 +0800
Subject: [PATCH 03/10] FOR_UPSTREAM [VPG]: drm/i915: Add trace for execlist
 state.

This commit adds trace events to track execlist state.

Tracked-On: https://jira01.devtools.intel.com/browse/OAM-26200
Change-Id: Ia64453f3fee9453ef1626fea470a4ee7a971c174
Signed-off-by: River, Li <river.li@intel.com>
Reviewed-on: https://android.intel.com:443/477655
---
 drivers/gpu/drm/i915/i915_trace.h | 100 ++++++++++++++++++++++++++++++++++++++
 drivers/gpu/drm/i915/intel_lrc.c  |   5 ++
 2 files changed, 105 insertions(+)

diff --git a/drivers/gpu/drm/i915/i915_trace.h b/drivers/gpu/drm/i915/i915_trace.h
index c75e240..3582e5c 100644
--- a/drivers/gpu/drm/i915/i915_trace.h
+++ b/drivers/gpu/drm/i915/i915_trace.h
@@ -1190,6 +1190,106 @@ DEFINE_EVENT(i915_suspend_resume_exit, intel_runtime_resume_exit,
 	TP_ARGS(dev, ret)
 );
 
+TRACE_EVENT(execlists_elsp_write,
+	TP_PROTO(struct intel_engine_cs *ring, u32 desc0,
+			u32 desc1, u32 desc2, u32 desc3),
+
+	TP_ARGS(ring, desc0, desc1, desc2, desc3),
+
+	TP_STRUCT__entry(
+		__field(u32, ring)
+		__field(u32, desc0)
+		__field(u32, desc1)
+		__field(u32, desc2)
+		__field(u32, desc3)
+	),
+
+	TP_fast_assign(
+		__entry->ring = ring->id;
+		__entry->desc0 = desc0;
+		__entry->desc1 = desc1;
+		__entry->desc2 = desc2;
+		__entry->desc3 = desc3;
+	),
+
+	TP_printk("ring=%u,desc0=%u,desc1=%u,desc2=%u,desc3=%u",
+		__entry->ring, __entry->desc0, __entry->desc1,
+		__entry->desc2, __entry->desc3)
+);
+
+
+TRACE_EVENT(execlists_context_unqueue,
+	TP_PROTO(struct intel_engine_cs *ring,
+		 struct intel_ctx_submit_request *req0,
+		 struct intel_ctx_submit_request *req1),
+
+	TP_ARGS(ring, req0, req1),
+
+	TP_STRUCT__entry(
+		__field(u32, ring)
+		__field(struct intel_context *, ctx0)
+		__field(u32, req0_tail)
+		__field(struct intel_context *, ctx1)
+		__field(u32, req1_tail)
+	),
+
+	TP_fast_assign(
+		__entry->ring = ring->id;
+		__entry->ctx0 = req0 ? req0->ctx : NULL;
+		__entry->req0_tail = req0 ? req0->tail : 0;
+		__entry->ctx1 = req1 ? req1->ctx : NULL;
+		__entry->req1_tail = req1 ? req1->tail : 0;
+	),
+
+	TP_printk("ring=%u,req0->ctx=%p,req0->tail=%u,req1->ctx=%p,req1->tail=%u",
+		__entry->ring, __entry->ctx0, __entry->req0_tail,
+		__entry->ctx1, __entry->req1_tail)
+);
+
+TRACE_EVENT(intel_execlists_handle_ctx_events,
+	TP_PROTO(struct intel_engine_cs *ring, u32 status_pointer,
+			u32 read_pointer),
+
+	TP_ARGS(ring, status_pointer, read_pointer),
+
+	TP_STRUCT__entry(
+		__field(u32, ring)
+		__field(u32, status_pointer)
+		__field(u32, read_pointer)
+	),
+
+	TP_fast_assign(
+		__entry->ring = ring->id;
+		__entry->status_pointer = status_pointer;
+		__entry->read_pointer = read_pointer;
+	),
+
+	TP_printk("ring=%d,read_pointer=%d,write_pointer=%d,status=0x%x",
+		__entry->ring, __entry->read_pointer,
+		__entry->status_pointer & 0x07, __entry->status_pointer)
+);
+
+TRACE_EVENT(execlists_context_queue,
+	TP_PROTO(struct intel_ctx_submit_request *req),
+
+	TP_ARGS(req),
+
+	TP_STRUCT__entry(
+		__field(struct intel_context *, ctx)
+		__field(u32, ring)
+		__field(u32, tail)
+	),
+
+	TP_fast_assign(
+		__entry->ctx  = req->ctx;
+		__entry->ring = req->ring->id;
+		__entry->tail = req->tail;
+	),
+
+	TP_printk("ring=%u,ctx=%p,req->tail=%u",
+		__entry->ring, __entry->ctx, __entry->tail)
+);
+
 #endif /* _I915_TRACE_H_ */
 
 /* This part must be outside protection */
diff --git a/drivers/gpu/drm/i915/intel_lrc.c b/drivers/gpu/drm/i915/intel_lrc.c
index a642cf9..4b76019 100644
--- a/drivers/gpu/drm/i915/intel_lrc.c
+++ b/drivers/gpu/drm/i915/intel_lrc.c
@@ -319,6 +319,7 @@ static void execlists_elsp_write(struct intel_engine_cs *ring,
 	desc[3] = (u32)(temp >> 32);
 	desc[2] = (u32)temp;
 
+	trace_execlists_elsp_write(ring, desc[0], desc[1], desc[2], desc[3]);
 	/* Set Force Wakeup bit to prevent GT from entering C6 while ELSP writes
 	 * are in progress.
 	 *
@@ -802,6 +803,7 @@ static void execlists_context_unqueue(struct intel_engine_cs *ring)
 		return;
 
 	execlists_fetch_requests(ring, &req0, &req1);
+	trace_execlists_context_unqueue(ring, req0, req1);
 
 	/* check for a simulated hang request */
 	if (intel_ring_stopped(ring)) {
@@ -1111,6 +1113,8 @@ int intel_execlists_handle_ctx_events(struct intel_engine_cs *ring, bool do_lock
 	if (read_pointer > write_pointer)
 		write_pointer += GEN8_CSB_ENTRIES;
 
+	trace_intel_execlists_handle_ctx_events(ring, status_pointer,
+		    read_pointer);
 	while (read_pointer < write_pointer) {
 		read_pointer++;
 
@@ -1191,6 +1195,7 @@ static int execlists_context_queue(struct intel_engine_cs *ring,
 	req->ring = ring;
 	req->tail = tail;
 
+	trace_execlists_context_queue(req);
 	if (IS_GEN8(ring->dev)) {
 		struct intel_ringbuffer *ringbuf = to->engine[ring->id].ringbuf;
 		/*
-- 
1.9.1

